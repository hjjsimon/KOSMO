# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dP5AIwE9-onwoEAHqoDur-CZicJbDIUK
"""

# I | í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
import warnings
warnings.filterwarnings('ignore')

# íŒë‹¤ìŠ¤, ë„˜íŒŒì´, ë§·í”Œë¡¯ë¦½, ì”¨ë³¸ ë“± ë°ì´í„° ì²˜ë¦¬ ë° ì‹œê°í™”ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# OneHotEncoderì™€ 3D í”Œë¡œíŒ…ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
from sklearn.preprocessing import OneHotEncoder
from mpl_toolkits.mplot3d import Axes3D

# ë°ì´í„°ì…‹ ë¡œë“œí•˜ê¸°
data = pd.read_csv('/content/drive/MyDrive/healthcare-dataset-stroke-data.csv')

# ì¶œë ¥
print(data.head)

# 1) ë‹¨ë³€ëŸ‰ ë¶„ì„
# I | ëª©í‘œ ë³€ìˆ˜

# ëª¨ë“  ê·¸ë˜í”„ì˜ ìŠ¤íƒ€ì¼ì„ seabornìœ¼ë¡œ ì„¤ì •
sns.set_style("whitegrid")

# 'stroke' ëª©í‘œ ë³€ìˆ˜ë¥¼ ê·¸ë¦½ë‹ˆë‹¤.
plt.figure(figsize=(6, 6))
sns.countplot(x=data['stroke'])
plt.title('Distribution of Target Variable (Stroke)')
plt.show()

# II | ë²”ì£¼í˜• ë³€ìˆ˜

# ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ëª©ë¡
# ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” 'ì„±ë³„', 'ê³ í˜ˆì••', 'ì‹¬ì¥ ì§ˆí™˜', 'ê²°í˜¼ ì—¬ë¶€', 'ì§ì—… ìœ í˜•', 'ê±°ì£¼ ìœ í˜•', 'í¡ì—° ìƒíƒœ' ì…ë‹ˆë‹¤.
categorical_variables = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']

# ë§‰ëŒ€ ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
fig, axs = plt.subplots(nrows=4, ncols=2, figsize=(15, 20))

# ê° ë³€ìˆ˜ì™€ ì„œë¸Œí”Œë¡¯ì— ëŒ€í•´, ë°ì´í„°ì—ì„œ ë³€ìˆ˜ì˜ ì¹´ìš´íŠ¸ í”Œë¡¯ì„ ê·¸ë¦½ë‹ˆë‹¤. ë˜í•œ ê° ì„œë¸Œí”Œë¡¯ì˜ xì¶• ë ˆì´ë¸”ì„ íšŒì „ì‹œì¼œ ê°€ë…ì„±ì„ ë†’ì…ë‹ˆë‹¤.
for var, subplot in zip(categorical_variables, axs.flatten()):
    sns.countplot(x=var, data=data, ax=subplot)
    for label in subplot.get_xticklabels():
        label.set_rotation(30)

plt.tight_layout()
plt.show()

# III | ì—°ì†í˜• ë³€ìˆ˜

# ì—°ì†í˜• ë³€ìˆ˜ ëª©ë¡
continuous_variables = ['age', 'avg_glucose_level', 'bmi']

# ì—°ì†í˜• ë³€ìˆ˜ì— ëŒ€í•œ íˆìŠ¤í† ê·¸ë¨ ê·¸ë¦¬ê¸°
fig, axs = plt.subplots(1, 3, figsize=(20, 5))

for var, subplot in zip(continuous_variables, axs.flatten()):
    sns.histplot(data[var], kde=True, ax=subplot)

plt.tight_layout()
plt.show()

# ì—°ì†í˜• ë³€ìˆ˜ì— ëŒ€í•œ ë°•ìŠ¤í”Œë¡¯ ê·¸ë¦¬ê¸°
fig, axs = plt.subplots(1, 3, figsize=(20, 5))

for var, subplot in zip(continuous_variables, axs.flatten()):
    sns.boxplot(data[var], ax=subplot)

plt.tight_layout()
plt.show()

# 2) ì´ë³€ëŸ‰ ë¶„ì„

# 'ë‡Œì¡¸ì¤‘'ì´ë¼ëŠ” ëª©í‘œ ë³€ìˆ˜ì— ëŒ€í•´ ë²”ì£¼í˜• ë³€ìˆ˜ë“¤ì„ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë´…ë‹ˆë‹¤.
fig, axs = plt.subplots(3, 3, figsize=(20, 20))

for var, subplot in zip(categorical_variables, axs.flatten()):
    sns.countplot(x=data[var], hue=data['stroke'], ax=subplot)
    for label in subplot.get_xticklabels():
        label.set_rotation(90)

plt.tight_layout()
plt.show()

# 'ë‡Œì¡¸ì¤‘'ì´ë¼ëŠ” ëª©í‘œ ë³€ìˆ˜ì— ëŒ€í•´ ì—°ì†í˜• ë³€ìˆ˜ë“¤ì„ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë´…ë‹ˆë‹¤.
fig, axs = plt.subplots(1, 3, figsize=(20, 5))

for var, subplot in zip(continuous_variables, axs.flatten()):
    sns.violinplot(x=data['stroke'], y=data[var], ax=subplot)

plt.tight_layout()
plt.show()

# 3) ë‹¤ë³€ëŸ‰ ë¶„ì„

# ì›ë³¸ ë°ì´í„°ì…‹ ë‹¤ì‹œ ë¡œë“œí•˜ê¸°
data_original = pd.read_csv('/content/drive/MyDrive/healthcare-dataset-stroke-data.csv')
data_original = data_original.drop("id",axis=1)

# ë²”ì£¼í˜• ì—´ ì„ íƒí•˜ê¸°
categorical_cols = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']

# ë²”ì£¼í˜• ì—´ì— ì›-í•« ì¸ì½”ë”© ì ìš©í•˜ê¸°
one_hot_encoder = OneHotEncoder(drop='first', sparse=False)
one_hot_encoded = one_hot_encoder.fit_transform(data_original[categorical_cols])

# ì›-í•« ì¸ì½”ë”©ëœ ë°°ì—´ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ê¸°
one_hot_encoded_df = pd.DataFrame(one_hot_encoded, columns=one_hot_encoder.get_feature_names_out(categorical_cols))

# ì›ë³¸ ë²”ì£¼í˜• ì—´ì„ ë°ì´í„°ì…‹ì—ì„œ ì‚­ì œí•˜ê¸°
data_original.drop(categorical_cols, axis=1, inplace=True)

# ì›-í•« ì¸ì½”ë”©ëœ ë°ì´í„°í”„ë ˆì„ê³¼ ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ê²°í•©í•˜ê¸°
data_one_hot_encoded = pd.concat([data_original, one_hot_encoded_df], axis=1)

# ì›-í•« ì¸ì½”ë”©ëœ ë°ì´í„°ì— ëŒ€í•œ ìƒê´€ í–‰ë ¬ ê³„ì‚°í•˜ê¸°
correlation_matrix_one_hot = data_one_hot_encoded.corr()

# ì „ì²´ ìƒê´€ í–‰ë ¬ì— ëŒ€í•œ íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°
plt.figure(figsize=(15, 10))
sns.heatmap(correlation_matrix_one_hot, annot=False, cmap='coolwarm', linewidths=0.5)
plt.title("Correlation Matrix Heatmap (One-Hot Encoded Data)")
plt.show()

# ê° íŠ¹ì„±ê³¼ ëª©í‘œ ë³€ìˆ˜ 'stroke'ì™€ì˜ ìƒê´€ê´€ê³„ ê³„ì‚°í•˜ê¸°
target_corr_one_hot = correlation_matrix_one_hot['stroke'].drop('stroke')

# ìƒê´€ ê°’ë“¤ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê¸°
target_corr_sorted_one_hot = target_corr_one_hot.sort_values(ascending=False)

# ëª©í‘œ ì—´ê³¼ì˜ ìƒê´€ê´€ê³„ì— ëŒ€í•œ íˆíŠ¸ë§µ ê·¸ë¦¬ê¸°
plt.figure(figsize=(5, 10))
sns.set(font_scale=0.8)
sns.set_style("white")
sns.set_palette("PuBuGn_d")
sns.heatmap(target_corr_sorted_one_hot.to_frame(), cmap="coolwarm", annot=True, fmt='.2f', cbar=False)
plt.title('Correlation with Stroke (One-Hot Encoded Data)')
plt.show()

# 'age'(ì—°ë ¹)ì™€ 'work_type'(ì§ì—… ìœ í˜•)ì˜ ê´€ê³„ë¥¼ ìƒì ê·¸ë¦¼(boxplot)ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
plt.figure(figsize=(10, 6))
sns.boxplot(x=data['work_type'], y=data['age'], hue=data['stroke'])
plt.title('Age vs Work Type')
plt.xticks(rotation=90)
plt.show()

# 'avg_glucose_level'(í‰ê·  í˜ˆë‹¹ ìˆ˜ì¤€)ê³¼ 'smoking_status'(í¡ì—° ìƒíƒœ)ì˜ ê´€ê³„ë¥¼ ìƒì ê·¸ë¦¼ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
plt.figure(figsize=(10, 6))
sns.boxplot(x=data['smoking_status'], y=data['avg_glucose_level'], hue=data['stroke'])
plt.title('Average Glucose Level vs Smoking Status')
plt.xticks(rotation=90)
plt.show()

# 'bmi'(ì²´ì§ˆëŸ‰ ì§€ìˆ˜)ì™€ 'gender'(ì„±ë³„)ì˜ ê´€ê³„ë¥¼ ìƒì ê·¸ë¦¼ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.
plt.figure(figsize=(10, 6))
sns.boxplot(x=data['gender'], y=data['bmi'], hue=data['stroke'])
plt.title('BMI vs Gender')
plt.xticks(rotation=90)
plt.show()

# 'age', 'avg_glucose_level', 'bmi', 'stroke' ë³€ìˆ˜ë¥¼ í¬í•¨í•˜ëŠ” ë°ì´í„°ì˜ ë¶€ë¶„ì§‘í•©(subset)ì„ ìƒì„±í•©ë‹ˆë‹¤
subset = data[['age', 'avg_glucose_level', 'bmi', 'stroke']]

# 'stroke' ë³€ìˆ˜ë¥¼ ë²”ì£¼í˜• ë³€ìˆ˜(category)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì´ê²ƒì€ pairplot ìƒì„±ì— í•„ìš”í•œ ì „ì²˜ë¦¬ ë‹¨ê³„ì…ë‹ˆë‹¤.
subset['stroke'] = subset['stroke'].astype('category')

# ìƒì„±ëœ ë¶€ë¶„ì§‘í•©ì„ ë°”íƒ•ìœ¼ë¡œ pairplotì„ ìƒì„±í•©ë‹ˆë‹¤.
sns.pairplot(subset, hue='stroke', plot_kws={'alpha': 0.5})
plt.show()

# 'stroke' ë³€ìˆ˜ì— ëŒ€í•œ ìƒ‰ìƒ ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.
colors = data['stroke'].map({0:'blue', 1:'red'})

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# 3D ì‚°ì ë„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
ax.scatter(data['age'], data['avg_glucose_level'], data['bmi'], c=colors, alpha=0.6, edgecolors='w')

ax.set_xlabel('Age')
ax.set_ylabel('Average Glucose Level')
ax.set_zlabel('BMI')
plt.show()

# EDA ê²°ê³¼ & í† ì˜

# ê²°ê³¼:
# íƒ€ê²Ÿ ë³€ìˆ˜ì¸ ì¤‘í’ˆì¦ì€ í´ë˜ìŠ¤ 0 (ë‡Œì¡¸ì¤‘ ì—†ìŒ)ì´ í´ë˜ìŠ¤ 1 (ë‡Œì¡¸ì¤‘ ìˆìŒ)ë³´ë‹¤ ì›”ë“±íˆ ë§ì•„ ë§¤ìš° ë¶ˆê· í˜•í•œ ë¶„í¬ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ì´ëŠ” ê¸°ê³„ í•™ìŠµ ëª¨ë¸ì˜ ì„ íƒê³¼ í‰ê°€ ì§€í‘œì— ì˜í–¥ì„ ë¯¸ì¹  ì¤‘ìš”í•œ ê´€ì°° ê²°ê³¼ì…ë‹ˆë‹¤. â—

# ì„±ë³„, ê³ í˜ˆì••, ì‹¬ì¥ ì§ˆí™˜, ê²°í˜¼ ì—¬ë¶€, ì§ì—… ìœ í˜•, ê±°ì£¼ ìœ í˜•, í¡ì—° ìƒíƒœ ë“±ì˜ ë²”ì£¼í˜• ë³€ìˆ˜ëŠ” ë‹¤ì–‘í•œ ë¶„í¬ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. íŠ¹íˆ, ê³ í˜ˆì••ê³¼ ì‹¬ì¥ ì§ˆí™˜ì€ ë‡Œì¡¸ì¤‘ í™˜ìë“¤ ì‚¬ì´ì—ì„œ ë” ìì£¼ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ğŸ‘¥ğŸ©ºâ¤ï¸

# ì—°ë ¹, í‰ê·  ê¸€ë£¨ì½”ìŠ¤ ë ˆë²¨, BMIì™€ ê°™ì€ ì—°ì† ë³€ìˆ˜ë“¤ì€ ê°ê° ë‹¤ë¥¸ ë¶„í¬ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤. ë‡Œì¡¸ì¤‘ í™˜ìë“¤ì—ì„œëŠ” ë‚˜ì´ì™€ í‰ê·  ê¸€ë£¨ì½”ìŠ¤ ë ˆë²¨ì´ ë” ë†’ì•˜ì§€ë§Œ, ë‡Œì¡¸ì¤‘ í™˜ìì™€ ë¹„ë‡Œì¡¸ì¤‘ í™˜ì ì‚¬ì´ì—ì„œ BMIì—ëŠ” í° ì°¨ì´ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤. ğŸ“ŠğŸ”

# ì´ë³€ëŸ‰ ë° ë‹¤ë³€ëŸ‰ ë¶„ì„ ê²°ê³¼, ë‡Œì¡¸ì¤‘ í™˜ìë“¤ì´ ë³´í†µ ë‚˜ì´ê°€ ë§ê³  ê¸€ë£¨ì½”ìŠ¤ ë ˆë²¨ì´ ë†’ì€ ê²½í–¥ì´ ìˆìœ¼ë¯€ë¡œ, ë‚˜ì´ì™€ í‰ê·  ê¸€ë£¨ì½”ìŠ¤ ë ˆë²¨ì´ ë‡Œì¡¸ì¤‘ì˜ ê°•ë ¥í•œ ì˜ˆì¸¡ ë³€ìˆ˜ê°€ ë  ìˆ˜ ìˆìŒì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤. ğŸ‘´ğŸ©¸

# ë˜í•œ ì´ëŸ¬í•œ ë¶„ì„ì„ í†µí•´ BMIëŠ” ë‡Œì¡¸ì¤‘ì˜ ê°•ë ¥í•œ ì˜ˆì¸¡ ë³€ìˆ˜ê°€ ì•„ë‹ ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•˜ì˜€ìŠµë‹ˆë‹¤. ë‡Œì¡¸ì¤‘ í™˜ìì™€ ë¹„ë‡Œì¡¸ì¤‘ í™˜ì ì‚¬ì´ì—ì„œ BMIì˜ ë¶„í¬ëŠ” ë¹„ìŠ·í•˜ì˜€ìŠµë‹ˆë‹¤. âš–ï¸

# ê³ ê¸‰ ì‹œê°í™” (FacetGrid ë° í‰í–‰ ì¢Œí‘œ í”Œë¡¯)ì—ì„œëŠ” ë‚˜ì´ ë§ì€ í™˜ìë“¤, íŠ¹íˆ ìì˜ì—…ì ë˜ëŠ” ë¯¼ê°„ ê¸°ì—…ì— ì¢…ì‚¬í•˜ëŠ” ì‚¬ëŒë“¤ì´ ë‡Œì¡¸ì¤‘ì„ ë” ìì£¼ ê²ªëŠ” ê²ƒìœ¼ë¡œ ê´€ì°°ë˜ì—ˆìŠµë‹ˆë‹¤. ë˜í•œ, ë‡Œì¡¸ì¤‘ í™˜ìë“¤ì€ ì¼ë°˜ì ìœ¼ë¡œ ê·¸ë“¤ì˜ ì§ì—… ìœ í˜•ê³¼ ì„±ë³„ì— ê´€ê³„ì—†ì´ ë” ë†’ì€ ê¸€ë£¨ì½”ìŠ¤ ë ˆë²¨ì„ ê°€ì§€ê³  ìˆì—ˆìŠµë‹ˆë‹¤. ğŸ“ŠğŸ‘¥ğŸ‘¨â€ğŸ’¼ğŸ‘©â€ğŸ’¼ğŸ‘´ğŸ©¸

# í† ë¡ :
# íƒìƒ‰ì  ë°ì´í„° ë¶„ì„(EDA)ì€ ë‡Œì¡¸ì¤‘ê³¼ ê´€ë ¨ëœ ìš”ì¸ì— ëŒ€í•œ ê·€ì¤‘í•œ í†µì°°ì„ ì œê³µí–ˆìŠµë‹ˆë‹¤. ë‚˜ì´, ê³ í˜ˆì••, ì‹¬ì¥ ì§ˆí™˜, í‰ê·  ê¸€ë£¨ì½”ìŠ¤ ë ˆë²¨ì´ ì¤‘ìš”í•œ ìš”ì¸ìœ¼ë¡œ ë³´ì´ë©°, ë°˜ë©´ BMIëŠ” ì¤‘ìš”í•œ ì˜ˆì¸¡ ë³€ìˆ˜ê°€ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì •ë³´ëŠ” íŠ¹ì„± ì„ íƒê³¼ ëª¨ë¸ë§ ê³¼ì •ì„ ì•ˆë‚´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, íƒ€ê²Ÿ ë³€ìˆ˜ì˜ ë¶ˆê· í˜•ì€ ì˜ˆì¸¡ ëª¨ë¸ì„ ë§Œë“œëŠ” ë° ì–´ë ¤ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¶ˆê· í˜•ì„ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ì†Œìˆ˜ í´ë˜ìŠ¤ì˜ ì˜¤ë²„ìƒ˜í”Œë§, ë‹¤ìˆ˜ í´ë˜ìŠ¤ì˜ ì–¸ë”ìƒ˜í”Œë§ ë˜ëŠ” ë‘˜ ë‹¤ë¥¼ ì‚¬ìš©í•˜ëŠ” SMOTEì™€ ê°™ì€ ê¸°ë²•ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ“ˆğŸ”

# ë˜í•œ, EDAê°€ ëª‡ ê°€ì§€ ê·€ì¤‘í•œ í†µì°°ì„ ì œê³µí–ˆì§€ë§Œ, ìƒê´€ ê´€ê³„ê°€ ì¸ê³¼ ê´€ê³„ë¥¼ ì˜ë¯¸í•˜ì§€ëŠ” ì•ŠìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìš”ì¸ë“¤ê³¼ ë‡Œì¡¸ì¤‘ ê°„ì˜ ì¸ê³¼ ê´€ê³„ë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ ë³´ë‹¤ ì² ì €í•œ í†µê³„ ë¶„ì„ ë˜ëŠ” ì‹¤í—˜ ì—°êµ¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ“šğŸ”¬

# ë§ˆì§€ë§‰ìœ¼ë¡œ, EDAëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„°ì™€ ë³€ìˆ˜ì— í•œì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ë°ì´í„° ì„¸íŠ¸ì— í¬í•¨ë˜ì§€ ì•Šì€ ë‡Œì¡¸ì¤‘ê³¼ ê´€ë ¨ëœ ë‹¤ë¥¸ ì¤‘ìš”í•œ ìš”ì¸ë“¤, ì˜ˆë¥¼ ë“¤ì–´ ë‡Œì¡¸ì¤‘ì˜ ê°€ì¡±ë ¥, ì‹ë‹¨, ì‹ ì²´ í™œë™, ì•Œì½”ì˜¬ ì„­ì·¨, ìŠ¤íŠ¸ë ˆìŠ¤ ìˆ˜ì¤€ ë“±ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ìš”ì¸ë“¤ì„ í¬í•¨í•˜ë©´ ë³´ë‹¤ ì¢…í•©ì ì¸ ë¶„ì„ì´ ê°€ëŠ¥í•´ì§ˆ ê²ƒì…ë‹ˆë‹¤. ğŸ“ŠğŸ”¬ğŸ“

# ë°ì´í„° ì •ì œ
# ë°ì´í„° í´ë Œì§• ê³¼ì •ì€ ë‹¤ìŒ ë‹¨ê³„ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤:
# ê²°ì¸¡ì¹˜ í™•ì¸ ë° ì²˜ë¦¬: 'bmi'ì™€ ê°™ì€ ì—´ì—ëŠ” ì±„ì›Œì•¼ í•˜ê±°ë‚˜ í–‰ì„ ì œê±°í•´ì•¼ í•˜ëŠ” ê²°ì¸¡ì¹˜ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìƒí™©ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤. â—

# ì¤‘ë³µê°’ í™•ì¸ ë° ì²˜ë¦¬: ë°ì´í„°ì…‹ì— ì¤‘ë³µëœ í–‰ì´ ì—†ëŠ”ì§€ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤. ì¤‘ë³µì´ ìˆë‹¤ë©´, ë°ì´í„°ì˜ íŠ¹ì„±ê³¼ ì—°êµ¬ ì§ˆë¬¸ì— ë”°ë¼ í•˜ë‚˜ë¥¼ ìœ ì§€í•˜ê±°ë‚˜ ëª¨ë“  ì¤‘ë³µì„ ìœ ì§€í•˜ê±°ë‚˜ ì¤‘ë³µì˜ í‰ê· ì„ ê³„ì‚°í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ”

# ì´ìƒì¹˜ í™•ì¸ ë° ì²˜ë¦¬: 'avg_glucose_level'ê³¼ 'bmi'ì™€ ê°™ì€ ëª‡ëª‡ ì—´ì€ ìˆ˜ì¹˜í˜•ì´ë©° ë¶„ì„ì„ ì™œê³¡í•  ìˆ˜ ìˆëŠ” ì´ìƒì¹˜ë¥¼ í¬í•¨í•˜ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ ì œê±°í•˜ê±°ë‚˜ ê·¸ ì˜í–¥ì„ ì¤„ì´ê¸° ìœ„í•´ ë³€í™˜ì„ ì ìš©í•˜ëŠ” ë“± ì´ìƒì¹˜ë¥¼ ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ê²°ì •í•´ì•¼ í•©ë‹ˆë‹¤. ğŸ“ˆ

# ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì ì ˆí•œ ë°ì´í„° ìœ í˜•ìœ¼ë¡œ ë³€í™˜: 'gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status' ê°™ì€ ì—´ì€ ë²”ì£¼í˜•ì…ë‹ˆë‹¤. ë¶„ì„ì— ë”°ë¼ ì´ë¥¼ ë”ë¯¸ ë³€ìˆ˜ë¡œ ë³€í™˜í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ“ŠğŸ“

# ì˜ëª»ëœ ê°’ í™•ì¸ ë° ì²˜ë¦¬: ì˜ˆë¥¼ ë“¤ì–´, 'age'ëŠ” ìŒìˆ˜ê°€ ì•„ë‹ˆì–´ì•¼ í•˜ë©°, 'hypertension'ê³¼ 'heart_disease'ëŠ” 0 ë˜ëŠ” 1ì´ì–´ì•¼ í•˜ë©°, 'gender'ëŠ” 'Male' ë˜ëŠ” 'Female'ì´ì–´ì•¼ í•©ë‹ˆë‹¤. âš ï¸

# ê²°ì¸¡ì¹˜

# ë°ì´í„° ë¡œë“œ
data = pd.read_csv('/content/drive/MyDrive/healthcare-dataset-stroke-data.csv')

# ê²°ì¸¡ì¹˜ í™•ì¸
data.isnull().sum()

from sklearn.neighbors import KNeighborsRegressor

def knn_impute(df, na_target):
    df = df.copy()

    numeric_df = df.select_dtypes(include=[np.number])
    non_na_columns = numeric_df.loc[: ,numeric_df.isna().sum() == 0].columns

    y_train = numeric_df.loc[numeric_df[na_target].isna() == False, na_target]
    X_train = numeric_df.loc[numeric_df[na_target].isna() == False, non_na_columns]
    X_test = numeric_df.loc[numeric_df[na_target].isna() == True, non_na_columns]

    knn = KNeighborsRegressor()
    knn.fit(X_train, y_train)

    y_pred = knn.predict(X_test)

    df.loc[df[na_target].isna() == True, na_target] = y_pred

    return df

na_cols = [col for col in data.columns if data[col].isnull().sum()!=0]

for col in na_cols:
    data = knn_impute(data, col)

# ê²°ì¸¡ì¹˜ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ì—¬ ê²€ì¦í•©ë‹ˆë‹¤
data.isnull().sum()

# ID ì—´ ì œê±°
data = data.drop('id',axis=1)

# ì¤‘ë³µ í–‰ í™•ì¸
duplicate_rows = data.duplicated()

# ì¤‘ë³µ í–‰ ìˆ˜ ê³„ì‚°
num_duplicate_rows = duplicate_rows.sum()

num_duplicate_rows
# 0

# IQR ë°©ë²•ì„ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def count_outliers(column):
    Q1 = column.quantile(0.25)
    Q3 = column.quantile(0.75)
    IQR = Q3 - Q1

    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    return ((column < lower_bound) | (column > upper_bound)).sum()

# 'age', 'avg_glucose_level', 'bmi'ì—ì„œ ì´ìƒì¹˜ í™•ì¸
outliers = {column: count_outliers(data[column]) for column in ['age', 'avg_glucose_level', 'bmi']}

outliers
# {'age': 0, 'avg_glucose_level': 627, 'bmi': 117}

# 'avg_glucose_level'ê³¼ 'bmi'ì—ì„œ 0 ë˜ëŠ” ìŒìˆ˜ ê°’ í™•ì¸
zero_or_negative_values = {column: (data[column] <= 0).sum() for column in ['avg_glucose_level', 'bmi']}

zero_or_negative_values
# {'avg_glucose_level': 0, 'bmi': 0}

# 'avg_glucose_level'ê³¼ 'bmi' ì—´ì—ëŠ” 0 ë˜ëŠ” ìŒìˆ˜ ê°’ì´ ì—†ìœ¼ë¯€ë¡œ ë¡œê·¸ ë³€í™˜ì„ ì•ˆì „í•˜ê²Œ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

# ì´ëŸ¬í•œ ì—´ì— ë¡œê·¸ ë³€í™˜ì„ ì ìš©í•˜ê³  ë‹¤ì‹œ ì´ìƒì¹˜ë¥¼ í™•ì¸í•´ë´…ì‹œë‹¤.

# ë¡œê·¸ ë³€í™˜

# ë¡œê·¸ ë³€í™˜ ì ìš©
data['avg_glucose_level'] = np.log(data['avg_glucose_level'])
data['bmi'] = np.log(data['bmi'])

# ë³€í™˜ í›„ 'avg_glucose_level'ê³¼ 'bmi'ì—ì„œ ì´ìƒì¹˜ í™•ì¸
outliers_transformed = {column: count_outliers(data[column]) for column in ['avg_glucose_level', 'bmi']}

print(outliers_transformed)

# ì—°ì† ë³€ìˆ˜ ëª©ë¡
continuous_variables = ['avg_glucose_level', 'bmi']

# ì—°ì† ë³€ìˆ˜ì˜ íˆìŠ¤í† ê·¸ë¨ í”Œë¡¯
fig, axs = plt.subplots(1, 2, figsize=(20, 5))

for var, subplot in zip(continuous_variables, axs.flatten()):
    sns.histplot(data[var], kde=True, ax=subplot)

plt.tight_layout()
plt.show()

# ì—°ì† ë³€ìˆ˜ì˜ ë°•ìŠ¤í”Œë¡¯ í”Œë¡¯
fig, axs = plt.subplots(1, 2, figsize=(20, 5))

for var, subplot in zip(continuous_variables, axs.flatten()):
    sns.boxplot(data[var], ax=subplot)

plt.tight_layout()
plt.show()
# {'avg_glucose_level': 380, 'bmi': 73}

# ë²”ì£¼í˜• ì—´ì—ì„œ ìœ ì¼í•œ ê°’ì„ í™•ì¸
unique_values_categorical = {column: data[column].unique() for column in ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']}

# 'ì„±ë³„'ì—ì„œ 'ê¸°íƒ€' ì¸ìŠ¤í„´ìŠ¤ì™€ 'í¡ì—°ìƒíƒœ'ì—ì„œ 'ì•Œ ìˆ˜ ì—†ìŒ' ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ë¥¼ ì„¸ê¸°
other_gender_count = (data['gender'] == 'Other').sum()
unknown_smoking_status_count = (data['smoking_status'] == 'Unknown').sum()

other_gender_count, unknown_smoking_status_count
# (1, 1544)

# 'ì„±ë³„'ì—ì„œ 'ê¸°íƒ€'ì— í•´ë‹¹í•˜ëŠ” í–‰ì„ ì‚­ì œ
data = data[data['gender'] != 'Other']

# ë²”ì£¼í˜• ë³€ìˆ˜ë¥¼ ì›-í•« ì¸ì½”ë”©ì„ ì‚¬ìš©í•˜ì—¬ ìˆ«ì í˜•ì‹ìœ¼ë¡œ ë³€í™˜
data_encoded = pd.get_dummies(data, columns=['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status'])

# 'ê³ í˜ˆì••', 'ì‹¬ì¥ì§ˆí™˜', 'ë‡Œì¡¸ì¤‘'ì—ì„œ ìœ ì¼í•œ ê°’ì„ í™•ì¸
unique_values_binary = {column: data[column].unique() for column in ['hypertension', 'heart_disease', 'stroke']}

unique_values_binary
# {'hypertension': array([0, 1]),
# 'heart_disease': array([1, 0]),
# 'stroke': array([1, 0])}

# ë°ì´í„°ì…‹ ë¡œë“œ
df = pd.read_csv('/content/drive/MyDrive/healthcare-dataset-stroke-data.csv')

# ì´ì „ì— ìˆ˜í–‰í•œ ë°ì´í„° í´ë Œì§• ê³¼ì • ì ìš©
df['bmi'].fillna(df['bmi'].median(), inplace=True)

# ë²”ì£¼í˜• ì—´
categorical_columns = ['gender', 'work_type', 'Residence_type', 'smoking_status']

# 'gender' ì—´ì—ì„œ ê°€ì¥ ë¹ˆë²ˆí•œ ì¹´í…Œê³ ë¦¬ ì°¾ê¸°
most_frequent_gender = df['gender'].value_counts().idxmax()

# 'Other'ë¥¼ ê°€ì¥ ë¹ˆë²ˆí•œ ì¹´í…Œê³ ë¦¬ì™€ í•©ì¹˜ê¸°
df['gender'] = df['gender'].replace('Other', most_frequent_gender)

# ë¡œê·¸ ë³€í™˜ ì ìš©
df['avg_glucose_level'] = np.log(df['avg_glucose_level'])
df['bmi'] = np.log(df['bmi'])

# ê°’ ë§¤í•‘í•˜ê³  'ever_married' ì—´ì— ì ìš©
df['ever_married'] = df['ever_married'].map({'No': 0, 'Yes': 1})

# ë²”ì£¼í˜• ë³€ìˆ˜ì— ì›-í•« ì¸ì½”ë”© ìˆ˜í–‰
df_encoded = pd.get_dummies(df, columns=categorical_columns)

# 'id' ì—´ ì‚­ì œ
df_encoded = df_encoded.drop(columns='id')

# íŠ¹ì„± ì¤‘ìš”ë„
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# í”¼ì²˜ í–‰ë ¬ Xì™€ íƒ€ê²Ÿ y ì •ì˜
X = df_encoded.drop(columns='stroke')
y = df_encoded['stroke']

# ë°ì´í„°ë¥¼ í›ˆë ¨ìš©ê³¼ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ë¶„ë¦¬
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¶„ë¥˜ê¸° ìƒì„±
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# ëª¨ë¸ì„ í›ˆë ¨ ë°ì´í„°ì— ì í•©ì‹œí‚¤ê¸°
rf.fit(X_train, y_train)

# í”¼ì²˜ ì¤‘ìš”ë„ ì–»ê¸°
feature_importances = rf.feature_importances_

# ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„°í”„ë ˆì„ ìƒì„±
importances_df = pd.DataFrame({
'Feature': X.columns,
'Importance': feature_importances
})

#ì¤‘ìš”ë„ë¥¼ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬
importances_df = importances_df.sort_values(by='Importance', ascending=False)

# í”¼ì²˜ ì¤‘ìš”ë„ í”Œë¡œíŒ…
plt.figure(figsize=(10, 8))
sns.barplot(data=importances_df, x='Importance', y='Feature', color='b')
plt.title('Feature Importance from Random Forest')
plt.xlabel('Importance')
plt.ylabel('Feature')
plt.show()

# BMIë¥¼ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def categorize_bmi(bmi):
    if bmi < 18.5:
        return 'ì²´ì¤‘ ë¶€ì¡±'
    elif 18.5 <= bmi < 25:
        return 'ì •ìƒ ì²´ì¤‘'
    elif 25 <= bmi < 30:
        return 'ê³¼ì²´ì¤‘'
    else:
        return 'ë¹„ë§Œ'

# 'bmi' ì—´ì— í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ 'bmi_category' ì—´ ìƒì„±
df_encoded['bmi_category'] = df_encoded['bmi'].apply(categorize_bmi)

# ë‚˜ì´ë¥¼ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def categorize_age(age):
    if age < 18:
        return 'ì•„ë™'
    elif 18 <= age < 65:
        return 'ì„±ì¸'
    else:
        return 'ë…¸ì¸'

# 'age' ì—´ì— í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ 'age_category' ì—´ ìƒì„±
df_encoded['age_category'] = df_encoded['age'].apply(categorize_age)

# ê±´ê°• ìœ„í—˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ ì •ì˜
def compute_health_risk_score(row):
    score = 0
    # ê°œì¸ì´ ê°€ì§„ ê° ìœ„í—˜ ìš”ì¸ë§ˆë‹¤ ì ìˆ˜ì— 1ì„ ë”í•¨
    if row['age_category'] == 'ë…¸ì¸':
        score += 1
    if row['hypertension'] == 1:
        score += 1
    if row['heart_disease'] == 1:
        score += 1
    if row['bmi_category'] in ['ê³¼ì²´ì¤‘', 'ë¹„ë§Œ']:
        score += 1
    if row['smoking_status_smokes'] == 1:
        score += 1
    return score

# í•¨ìˆ˜ë¥¼ ì „ì²´ DataFrameì— ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ 'health_risk_score' ì—´ ìƒì„±
df_encoded['health_risk_score'] = df_encoded.apply(compute_health_risk_score, axis=1)

# ì—…ë°ì´íŠ¸ëœ DataFrameì˜ ì²˜ìŒ ëª‡ í–‰ì„ í‘œì‹œ
df_encoded.head()
# age hypertension heart_disease ever_married avg_glucose_level bmi stroke gender_Female gender_Male work_type_Govt_job ... work_type_children Residence_type_Rural Residence_type_Urban smoking_status_Unknown smoking_status_formerly smoked smoking_status_never smoked smoking_status_smokes bmi_category age_category health_risk_score

# ìƒˆë¡œìš´ ë²”ì£¼í˜• ë³€ìˆ˜ì— ëŒ€í•´ ì›-í•« ì¸ì½”ë”© ìˆ˜í–‰
df_encoded = pd.get_dummies(df_encoded, columns=['bmi_category', 'age_category'])

# ì—…ë°ì´íŠ¸ëœ DataFrameì˜ ì²˜ìŒ ëª‡ í–‰ì„ í‘œì‹œ
df_encoded.head()
# age hypertension heart_disease ever_married avg_glucose_level bmi stroke gender_Female gender_Male work_type_Govt_job ... Residence_type_Urban smoking_status_Unknown smoking_status_formerly smoked smoking_status_never smoked smoking_status_smokes health_risk_score bmi_category_ì²´ì¤‘ ë¶€ì¡± age_category_ì„±ì¸ age_category_ì•„ë™ age_category_ë…¸ì¸

# ë¹„ìš©-ë¯¼ê° í•™ìŠµ
# ìš”ì•½

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt
import seaborn as sns

# ë°ì´í„°ì…‹ ë¶ˆëŸ¬ì˜¤ê¸°
df = pd.read_csv('/content/drive/MyDrive/healthcare-dataset-stroke-data.csv')

##-------ë°ì´í„° ì •ì œ-------##
na_cols = [col for col in df.columns if df[col].isnull().sum()!=0]

for col in na_cols:
    df = knn_impute(df, col)

# 'bmi' ì—´ì˜ ê²°ì¸¡ê°’ì„ ì¤‘ì•™ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
df['bmi'].fillna(df['bmi'].median(), inplace=True)

# 'gender' ì—´ì—ì„œ 'Other'ë¥¼ ê°€ì¥ ë¹ˆë„ê°€ ë†’ì€ ì¹´í…Œê³ ë¦¬ë¡œ í•©ì¹˜ê¸°
most_frequent_gender = df['gender'].value_counts().idxmax()
df['gender'] = df['gender'].replace('Other', most_frequent_gender)

##-------ë°ì´í„° ì¤€ë¹„-------##

# 'ever_married' ì—´ì˜ ê°’ì„ ë§¤í•‘í•˜ê³  ë°”ê¾¸ê¸°
df['ever_married'] = df['ever_married'].map({'No': 0, 'Yes': 1})

# ë²”ì£¼í˜• ë³€ìˆ˜ì— ì›-í•« ì¸ì½”ë”© ìˆ˜í–‰
categorical_columns = ['gender', 'work_type', 'Residence_type', 'smoking_status']
df_encoded = pd.get_dummies(df, columns=categorical_columns)

# 'id' ì—´ ì‚­ì œ
df_encoded = df_encoded.drop(columns='id')

#-------íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§------#

# íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ ìœ„í•œ í•¨ìˆ˜ ì •ì˜
def categorize_bmi(bmi):
    if bmi < 18.5:
        return 'Underweight'
    elif 18.5 <= bmi < 25:
        return 'Normal weight'
    elif 25 <= bmi < 30:
        return 'Overweight'
    else:
        return 'Obese'

def categorize_age(age):
    if age < 18:
        return 'Child'
    elif 18 <= age < 65:
        return 'Adult'
    else:
        return 'Senior'

def compute_health_risk_score(row):
    score = 0
    if row['age_category'] == 'Senior':
        score += 1
    if row['hypertension'] == 1:
        score += 1
    if row['heart_disease'] == 1:
        score += 1
    if row['bmi_category'] in ['Overweight', 'Obese']:
        score += 1
    if row['smoking_status_smokes'] == 1:
        score += 1
    return score

# í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ íŠ¹ì„± ìƒì„±
df_encoded['bmi_category'] = df_encoded['bmi'].apply(categorize_bmi)
df_encoded['age_category'] = df_encoded['age'].apply(categorize_age)
df_encoded['health_risk_score'] = df_encoded.apply(compute_health_risk_score, axis=1)

# ìƒˆë¡œìš´ ë²”ì£¼í˜• ë³€ìˆ˜ì— ì›-í•« ì¸ì½”ë”© ìˆ˜í–‰
df_encoded = pd.get_dummies(df_encoded, columns=['bmi_category', 'age_category'])

# íƒ€ê²Ÿ ë³€ìˆ˜ì—ì„œ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
df_encoded['stroke'].value_counts()
# 0 4861
# 1 249
# Name: stroke, dtype: int64

# ì˜ˆì¸¡í•˜ê¸°
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import TomekLinks
from imblearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, roc_auc_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.model_selection import learning_curve

# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ì •ì˜
X = df_encoded.drop('stroke', axis=1)
y = df_encoded['stroke']

# ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# íŒŒì´í”„ë¼ì¸ ì •ì˜

# íŒŒì´í”„ë¼ì¸ ì •ì˜
resampling = SMOTE(sampling_strategy='minority') # ì¬ìƒ˜í”Œë§ ì „ëµì„ 'minority'ë¡œ ì„¤ì •í•˜ì—¬ ì†Œìˆ˜ í´ë˜ìŠ¤ ì¬ìƒ˜í”Œë§
tomek = TomekLinks(sampling_strategy='majority') # ìƒ˜í”Œë§ ì „ëµì„ 'majority'ë¡œ ì„¤ì •í•˜ì—¬ ë‹¤ìˆ˜ í´ë˜ìŠ¤ ì–¸ë”ìƒ˜í”Œë§
scaler = StandardScaler()
model = XGBClassifier(scale_pos_weight=sum(y==0)/sum(y==1), # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë•Œë¬¸ì— í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •
eval_metric='logloss', # ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ logloss ì‚¬ìš©
use_label_encoder=False) # ê²½ê³  ë©”ì‹œì§€ë¥¼ í”¼í•˜ê¸° ìœ„í•´
pipeline = Pipeline([('StandardScaler', scaler), ('SMOTE', resampling), ('TomekLinks', tomek), ('Model', model)])

# ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ ì •ì˜
model = XGBClassifier(
    colsample_bytree=0.7,
    gamma=0.2,
    learning_rate=0.01,
    max_depth=7,
    min_child_weight=5,
    n_estimators=100,
    subsample=0.5,
    scale_pos_weight=sum(y_train==0)/sum(y_train==1), # í´ë˜ìŠ¤ ë¶ˆê· í˜• ë•Œë¬¸ì— í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì¡°ì •
    eval_metric='logloss', # ì„±ëŠ¥ í‰ê°€ë¥¼ ìœ„í•´ logloss ì‚¬ìš©
    use_label_encoder=False # ê²½ê³  ë©”ì‹œì§€ë¥¼ í”¼í•˜ê¸° ìœ„í•´
)

# ëª¨ë¸ í›ˆë ¨
model.fit(X_train, y_train)

# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì˜ˆì¸¡í•˜ê¸°
y_pred = model.predict(X_test)
y_score = model.predict_proba(X_test)[:,1]

# ë¶„ë¥˜ ë³´ê³ ì„œ

# ë¶„ë¥˜ ë³´ê³ ì„œ ì¶œë ¥
print(classification_report(y_test, y_pred))
# precision recall f1-score support

# ëª¨ë¸ ì ìš©í•˜ê¸°

# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œ ì˜ˆì¸¡í•˜ê¸°
y_pred = model.predict(X_test)

# í˜¼ë™ í–‰ë ¬ ê³„ì‚°
cm = confusion_matrix(y_test, y_pred, labels=model.classes_)

# ConfusionMatrixDisplay ê°ì²´ ìƒì„±
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)

# í˜¼ë™ í–‰ë ¬ í”Œë¡¯
disp.plot()
plt.show()

# ëª¨ë¸ ì ìš©í•˜ê¸°

# ROC ê³¡ì„ ê³¼ ROC ì˜ì—­ ê³„ì‚°
fpr_optimized, tpr_optimized, _ = roc_curve(y_test, y_pred)
roc_auc_optimized = auc(fpr_optimized, tpr_optimized)

# ROC ê³¡ì„  ê·¸ë¦¬ê¸°
plt.figure()
plt.plot(fpr_optimized, tpr_optimized, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_optimized)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

# ëª¨ë¸ ì ìš©í•˜ê¸°

# ì •ë°€ë„-ì¬í˜„ìœ¨ ê³¡ì„  ê·¸ë¦¬ê¸°
precision, recall, _ = precision_recall_curve(y_test, y_score)
plt.figure()
plt.plot(recall, precision, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall curve')
plt.legend(loc="lower left")

plt.show()

# í•™ìŠµ ê³¡ì„ 

# í•™ìŠµ ê³¡ì„  ê·¸ë¦¬ê¸°
train_sizes, train_scores, valid_scores = learning_curve(model, X, y, train_sizes=np.linspace(0.1, 1.0, 5), cv=5)
plt.figure()
plt.plot(train_sizes, train_scores.mean(axis=1), label='Training score')
plt.plot(train_sizes, valid_scores.mean(axis=1), label='Cross-validation score')
plt.xlabel('Training set size')
plt.ylabel('Score')
plt.title('Learning curve')
plt.legend(loc="lower right")
plt.show()

# ëª¨ë¸ ì €ì¥

# XGBoostì˜ save_model() ë©”ì†Œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.
model.save_model('model.xgb')

# !pip install sklearn2pmml sklearn-pandas

from sklearn2pmml import sklearn2pmml, make_pmml_pipeline
from sklearn_pandas import DataFrameMapper

mapper = DataFrameMapper([(col, None) for col in X_train.columns])
pipeline = make_pmml_pipeline(mapper, model)
sklearn2pmml(pipeline, 'XGBoost_model.pmml', with_repr=True)